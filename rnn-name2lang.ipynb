{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classifing last names with character-level RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.autograd import Variable\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset\n",
    "`wget https://github.com/hunkim/PyTorchZeroToAll/blob/master/data/names_train.csv.gz`\n",
    "\n",
    "`wget https://github.com/hunkim/PyTorchZeroToAll/blob/master/data/names_test.csv.gz`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[PosixPath('/data2/yinterian/name_dataset/names_test.csv'),\n",
       " PosixPath('/data2/yinterian/name_dataset/names_train.csv.gz'),\n",
       " PosixPath('/data2/yinterian/name_dataset/names_train.csv'),\n",
       " PosixPath('/data2/yinterian/name_dataset/names_test.csv.gz')]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "PATH = Path(\"/data2/yinterian/name_dataset/\")\n",
    "list(PATH.iterdir())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"Adsit\",\"Czech\"\r",
      "\r\n",
      "\"Ajdrna\",\"Czech\"\r",
      "\r\n",
      "\"Antonowitsch\",\"Czech\"\r",
      "\r\n",
      "\"Antonowitz\",\"Czech\"\r",
      "\r\n",
      "\"Ballalatak\",\"Czech\"\r",
      "\r\n",
      "\"Ballaltick\",\"Czech\"\r",
      "\r\n",
      "\"Bastl\",\"Czech\"\r",
      "\r\n",
      "\"Baroch\",\"Czech\"\r",
      "\r\n",
      "\"Betlach\",\"Czech\"\r",
      "\r\n",
      "\"Biganska\",\"Czech\"\r",
      "\r\n"
     ]
    }
   ],
   "source": [
    "! head /data2/yinterian/name_dataset/names_train.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Processing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "df = pd.read_csv(PATH/\"names_train.csv\", header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "55"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# getting a vocabulary of characters\n",
    "letters = [list(l) for l in df[0].values]\n",
    "vocab = sorted(list(set(np.concatenate(np.array(letters)))))\n",
    "vocab[:10]\n",
    "len(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab2id = {key:i for i, key in enumerate(vocab)}\n",
    "vocab2id[\" \"] # I am going to use 0 to pad sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "18"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels = sorted(df[1].unique())\n",
    "label2id = {key:i for i, key in enumerate(labels)}\n",
    "len(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = np.zeros(seq_length)\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pad_seq(x, seq_len=15, vocab2id=vocab2id):\n",
    "    x = list(x)\n",
    "    x = np.array([vocab2id[k] for k in x])\n",
    "    z = np.zeros(seq_length, dtype=np.int8)\n",
    "    n = min(seq_len, x.shape[0])\n",
    "    z[seq_len - n:] = x[0:n]\n",
    "    return z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0, 29, 29, 30, 30, 30],\n",
       "      dtype=int8)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = pad_seq(\"aabbb\")\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "def seq2matrix(x, vocab_len=55):\n",
    "    z = np.zeros((x.shape[0], vocab_len))\n",
    "    z[np.arange(len(x)), x] = 1\n",
    "    return z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NameDataset(Dataset):\n",
    "    def __init__(self, path, vocab2id, label2id, seq_len=15, vocab_len=55):\n",
    "        self.df = pd.read_csv(path, header=None)\n",
    "        self.label2id = label2id\n",
    "        self.vocab2id = vocab2id\n",
    "        self.seq_len = seq_len\n",
    "        self.vocab_len = vocab_len \n",
    "        self.x = df[0].values\n",
    "        self.y = [self.label2id[l] for l in df[1].values]\n",
    "        self.vocab2id = vocab2id\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.y)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        x = pad_seq(self.x[idx], self.seq_len, self.vocab2id)\n",
    "        x = seq2matrix(x, self.vocab_len)\n",
    "        return x, self.y[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = NameDataset(PATH/\"names_train.csv\", vocab2id, label2id)\n",
    "test = NameDataset(PATH/\"names_test.csv\", vocab2id, label2id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 2000\n",
    "n = len(test)\n",
    "train_dl = DataLoader(train, batch_size=batch_size)\n",
    "test_dl = DataLoader(test, batch_size=n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13374"
      ]
     },
     "execution_count": 178,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(15, 55) 2\n"
     ]
    }
   ],
   "source": [
    "x,y = train[0]\n",
    "print(x.shape,y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CharRNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "        super(CharRNN, self).__init__()\n",
    "\n",
    "        self.hidden_size = hidden_size\n",
    "        self.i2h = nn.Linear(input_size + hidden_size, hidden_size)\n",
    "        self.i2o = nn.Linear(input_size + hidden_size, output_size)\n",
    "        self.softmax = nn.LogSoftmax(dim=1)\n",
    "\n",
    "    def forward(self, x, hidden):\n",
    "        combined = torch.cat((x, hidden), 1)\n",
    "        hidden = self.i2h(combined)\n",
    "        output = self.i2o(combined)\n",
    "        output = self.softmax(output)\n",
    "        return output, hidden\n",
    "\n",
    "    def initHidden(self, bash_size):\n",
    "        return Variable(torch.zeros(bash_size, self.hidden_size))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Debugging model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "vocab_size = 55\n",
    "hidden_size = 100\n",
    "n_classes = 18\n",
    "model = CharRNN(vocab_size, hidden_size, n_classes).cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "x, y = next(iter(train_dl))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([2000, 15, 55]), torch.Size([2000]))"
      ]
     },
     "execution_count": 182,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape, y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "batch = x.shape[0]\n",
    "h = model.initHidden(batch).cuda()\n",
    "x = Variable(x).cuda().float()\n",
    "y = Variable(y).cuda().long()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2000, 155])"
      ]
     },
     "execution_count": 184,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cat((x[:,0], h), 1).size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "for ei in range(x.shape[1]):\n",
    "    x_t, h = model(x[:,ei], h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Variable containing:\n",
       " 2.8572\n",
       "[torch.cuda.FloatTensor of size 1 (GPU 0)]"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss = F.cross_entropy(x_t, y)\n",
    "loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size = 55\n",
    "hidden_size = 100\n",
    "n_classes = 18\n",
    "model = CharRNN(vocab_size, hidden_size, n_classes).cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_optimizer(model, lr = 0.01, wd = 0.00001):\n",
    "    parameters = filter(lambda p: p.requires_grad, model.parameters())\n",
    "    optim = torch.optim.Adam(parameters, lr=lr, weight_decay=wd)\n",
    "    return optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, optim):\n",
    "    model.train()\n",
    "    total = 0\n",
    "    sum_loss = 0\n",
    "    for i, (x, y) in enumerate(train_dl):\n",
    "        batch = x.shape[0]\n",
    "        h = model.initHidden(batch).cuda()\n",
    "        loss = 0\n",
    "        x = Variable(x).cuda().float()\n",
    "        y = Variable(y).cuda().long()\n",
    "        \n",
    "        for ei in range(x.shape[1]):\n",
    "            out, h = model(x[:,ei], h)\n",
    "        \n",
    "        loss = F.nll_loss(out, y)\n",
    "        \n",
    "        optim.zero_grad()\n",
    "        loss.backward(retain_graph=True)\n",
    "        optim.step()\n",
    "        total += batch\n",
    "        sum_loss += batch*(loss.data[0])\n",
    "    return sum_loss/total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(model, valid_dl):\n",
    "    model.eval()\n",
    "    res = []\n",
    "    x, y = next(iter(valid_dl))\n",
    "    x = Variable(x).cuda().float()\n",
    "    y = Variable(y).cuda().long()\n",
    "    N = x.shape[0]\n",
    "    h = model.initHidden(N).cuda()\n",
    "    for ei in range(x.shape[1]):\n",
    "        out, h = model(x[:,ei], h)\n",
    "    loss = F.nll_loss(out, y)\n",
    "    _, pred = torch.max(out.data, 1)\n",
    "    correct = pred.eq(y.data).cpu().sum()\n",
    "    print(\"loss and accuracy\", loss.data[0], correct/N)\n",
    "    return loss.data[0], correct/N "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size = 55\n",
    "hidden_size = 80\n",
    "n_classes = 18\n",
    "model = CharRNN(vocab_size, hidden_size, n_classes).cuda()\n",
    "optim = get_optimizer(model, lr =0.01, wd = 0.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss  2.6379703053519634\n",
      "loss  3.079397971237545\n",
      "loss  4.699799905358827\n",
      "loss  1.4068568627075246\n"
     ]
    }
   ],
   "source": [
    "for i in range(20):\n",
    "    loss = train(model, optim)\n",
    "    if i%5 == 1: print(\"loss \", loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss and accuracy 1.306892991065979 0.598175564528189\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(1.306892991065979, 0.598175564528189)"
      ]
     },
     "execution_count": 223,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict(model, test_dl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [],
   "source": [
    "optim = get_optimizer(model, lr =0.005, wd = 0.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss  1.3531686674591243\n",
      "loss  1.2070527767339985\n",
      "loss  1.1234513457195452\n",
      "loss  1.0495076240116266\n"
     ]
    }
   ],
   "source": [
    "for i in range(20):\n",
    "    loss = train(model, optim)\n",
    "    if i%5 == 1: print(\"loss \", loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss and accuracy 0.9648178219795227 0.7126514131897712\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.9648178219795227, 0.7126514131897712)"
      ]
     },
     "execution_count": 227,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict(model, test_dl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [],
   "source": [
    "optim = get_optimizer(model, lr =0.001, wd = 0.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss  0.9698967509015145\n",
      "loss  0.9602218927851489\n",
      "loss  0.9478184662004998\n",
      "loss  0.9370886844531185\n"
     ]
    }
   ],
   "source": [
    "for i in range(20):\n",
    "    loss = train(model, optim)\n",
    "    if i%5 == 1: print(\"loss \", loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss and accuracy 0.9145036935806274 0.7240915208613729\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.9145036935806274, 0.7240915208613729)"
      ]
     },
     "execution_count": 230,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict(model, test_dl)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model with word embeddings "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# References\n",
    "This notebook is a modified version of this tutorial\n",
    "http://pytorch.org/tutorials/intermediate/char_rnn_classification_tutorial.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  },
  "toc": {
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": "block",
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
