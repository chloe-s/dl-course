{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Attention for classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import unicode_literals, print_function, division\n",
    "from io import open\n",
    "import unicodedata\n",
    "import string\n",
    "import re\n",
    "import random\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch import optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading data files\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def unpack_dataset():\n",
    "    ! wget http://www.cs.cornell.edu/people/pabo/movie-review-data/rotten_imdb.tar.gz\n",
    "    ! mkdir data\n",
    "    ! tar -xvf rotten_imdb.tar.gz -C data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#unpack_dataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[PosixPath('data/plot.tok.gt9.5000'),\n",
       " PosixPath('data/subjdata.README.1.0'),\n",
       " PosixPath('data/quote.tok.gt9.5000')]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "PATH = Path(\"data\")\n",
    "list(PATH.iterdir())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We need each line in the file \n",
    "def read_file(path):\n",
    "    \"\"\" Read file returns a list of lines.\n",
    "    \"\"\"\n",
    "    with open(path, encoding = \"ISO-8859-1\") as f:\n",
    "        content = f.readlines()\n",
    "    return content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_content = read_file(PATH/\"quote.tok.gt9.5000\")\n",
    "obj_content = read_file(PATH/\"plot.tok.gt9.5000\")\n",
    "sub_content = np.array([line.strip().lower() for line in sub_content])\n",
    "obj_content = np.array([line.strip().lower() for line in obj_content])\n",
    "sub_y = np.zeros(len(sub_content))\n",
    "obj_y = np.ones(len(obj_content))\n",
    "X = np.append(sub_content, obj_content)\n",
    "y = np.append(sub_y, obj_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split dataset in train and validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Word to index mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "def get_vocab(content):\n",
    "    \"\"\"Computes Dict of counts of words.\n",
    "    \n",
    "    Computes the number of times a word is on a document.\n",
    "    \"\"\"\n",
    "    vocab = defaultdict(float)\n",
    "    for line in content:\n",
    "        words = set(line.split())\n",
    "        for word in words:\n",
    "            vocab[word] += 1\n",
    "    return vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "21415"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Getting the vocabulary from the training set\n",
    "word_count = get_vocab(X_train)\n",
    "len(word_count.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "for word in list(word_count):\n",
    "    if word_count[word] < 5:\n",
    "        del word_count[word]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4065"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(word_count.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Finally we need an index for each word in the vocab\n",
    "vocab2index = {\"<PAD>\":0, \"UNK\":1} # init with padding and unknown\n",
    "words = [\"<PAD>\", \"UNK\"]\n",
    "for word in word_count:\n",
    "    vocab2index[word] = len(words)\n",
    "    words.append(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "voc_size = len(words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sentence encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_sentence(s, N=40):\n",
    "    enc = np.zeros(N, dtype=np.int32)\n",
    "    enc1 = np.array([vocab2index.get(w, vocab2index[\"UNK\"]) for w in s.split()])\n",
    "    l = min(N, len(enc1))\n",
    "    enc[:l] = enc1[:l]\n",
    "    return enc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8000, 40)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train = np.vstack([encode_sentence(x) for x in X_train])\n",
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2000, 40)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_val = np.vstack([encode_sentence(x) for x in X_val])\n",
    "x_val.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SentenceDataset(Dataset):\n",
    "    def __init__(self, x, y):\n",
    "        \n",
    "        self.x = x\n",
    "        self.y = y\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.y)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return self.x[idx], self.y[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = SentenceDataset(x_train, y_train)\n",
    "valid_ds = SentenceDataset(x_val, y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 5\n",
    "train_dl = DataLoader(train_ds, batch_size=batch_size, shuffle=True)\n",
    "val_dl = DataLoader(valid_ds, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Encoder Model\n",
    "-----------\n",
    "The attention works like this [paper](https://www.cs.cmu.edu/~hovy/papers/16HLT-hierarchical-attention-networks.pdf). Let $w_t$ represents the words on a sentence $t \\in \\{1 \\dots T \\}$. $x_t$ the word embedding for $t$ and $h_t$ the output of the GRU for word $t$.\n",
    "\n",
    "$$u_t =  tanh(W_w h_t + b_w)$$\n",
    "$$\\alpha_t = \\frac{exp(u_t^T v_w)}{\\sum_t exp(u_t^T v_w)}$$\n",
    "$$s = \\sum_t \\alpha_t h_t$$\n",
    "\n",
    "\n",
    "The context vector $v_w$ can be seen as a high level representation of a fixed\n",
    "query \"what is the informative word\" over the words like that used in memory networks (Sukhbaatar et al., 2015; Kumar et al., 2015). The word context vector $v_w$ is randomly initialized and jointly learned during the training process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EncoderDecRNN(nn.Module):\n",
    "    def __init__(self, voc_size, emb_size=50, hidden_size=60):\n",
    "        super(EncoderDecRNN, self).__init__()\n",
    "\n",
    "        self.embedding = nn.Embedding(voc_size, emb_size, padding_idx=0)\n",
    "        self.gru = nn.GRU(emb_size, hidden_size, batch_first=True)\n",
    "        self.attn1 = nn.Linear(hidden_size, hidden_size)\n",
    "        self.attn2 = nn.Linear(hidden_size, 1, bias=False)\n",
    "        self.linear = nn.Linear(hidden_size, 1)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.embedding(x)\n",
    "        output, hidden = self.gru(x)\n",
    "        u = self.attn1(output)\n",
    "        alpha = F.softmax(self.attn2(u), dim=1)\n",
    "        s = (alpha*output).sum(1)\n",
    "        h_star = self.linear(s)\n",
    "        return h_star, alpha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "emb_size=50; hidden_size=20\n",
    "embedding = nn.Embedding(voc_size, emb_size, padding_idx=0)\n",
    "gru = nn.GRU(emb_size, hidden_size, batch_first=True)\n",
    "attn1 = nn.Linear(hidden_size, hidden_size)\n",
    "attn2 = nn.Linear(hidden_size, 1, bias=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "x, y = next(iter(train_dl))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([5, 40, 1])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emb = embedding(x.long())\n",
    "output, hidden = gru(emb)\n",
    "u = attn1(output)\n",
    "alpha = F.softmax(attn2(u), dim=1)\n",
    "\n",
    "alpha.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[torch.Size([20, 20]), torch.Size([20])]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[p.shape for p in attn1.parameters()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = EncoderDecRNN(voc_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "x, y = next(iter(train_dl))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_hat = model(x.long())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def val_metrics(model):\n",
    "    model.eval()\n",
    "    x = torch.LongTensor(x_val) #.cuda()\n",
    "    y = torch.Tensor(y_val).unsqueeze(1) #).cuda()\n",
    "    y_hat, _ = model(x)\n",
    "    loss = F.binary_cross_entropy_with_logits(y_hat, y)\n",
    "    y_pred = y_hat > 0\n",
    "    correct = (y_pred.float() == y).float().sum()\n",
    "    accuracy = correct/y_pred.shape[0]\n",
    "    return loss.item(), accuracy.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.6926704049110413, 0.5024999976158142)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_metrics(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 3000\n",
    "train_dl = DataLoader(train_ds, batch_size=batch_size, shuffle=True)\n",
    "val_dl = DataLoader(valid_ds, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training\n",
    "========"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_epocs(model, train_dl, epochs=10, lr=0.001):\n",
    "    parameters = filter(lambda p: p.requires_grad, model.parameters())\n",
    "    optimizer = torch.optim.Adam(parameters, lr=lr)\n",
    "    for i in range(epochs):\n",
    "        model.train()\n",
    "        sum_loss = 0.0\n",
    "        total = 0\n",
    "        for x, y in train_dl:\n",
    "            x = x.long()\n",
    "            y = y.float()\n",
    "            y_pred, _ = model(x)\n",
    "            optimizer.zero_grad()\n",
    "            loss = F.binary_cross_entropy_with_logits(y_pred, y.unsqueeze(1))\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            sum_loss += loss.item()*y.shape[0]\n",
    "            total += y.shape[0]\n",
    "        val_loss, val_acc = val_metrics(model)\n",
    "        print(\"train loss %.3f val loss %.3f val acc %.3f\"% (sum_loss/total, val_loss, val_acc))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = EncoderDecRNN(voc_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss 0.688 val loss 0.661 val acc 0.673\n",
      "train loss 0.632 val loss 0.535 val acc 0.746\n",
      "train loss 0.513 val loss 0.501 val acc 0.763\n",
      "train loss 0.449 val loss 0.437 val acc 0.805\n",
      "train loss 0.385 val loss 0.378 val acc 0.835\n",
      "train loss 0.325 val loss 0.351 val acc 0.845\n",
      "train loss 0.278 val loss 0.334 val acc 0.863\n",
      "train loss 0.238 val loss 0.317 val acc 0.871\n",
      "train loss 0.199 val loss 0.321 val acc 0.876\n",
      "train loss 0.170 val loss 0.301 val acc 0.885\n"
     ]
    }
   ],
   "source": [
    "train_epocs(model, train_dl, epochs=10, lr=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss 0.147 val loss 0.316 val acc 0.882\n",
      "train loss 0.140 val loss 0.313 val acc 0.883\n",
      "train loss 0.136 val loss 0.319 val acc 0.885\n",
      "train loss 0.131 val loss 0.319 val acc 0.885\n",
      "train loss 0.128 val loss 0.318 val acc 0.884\n",
      "train loss 0.124 val loss 0.320 val acc 0.885\n",
      "train loss 0.120 val loss 0.328 val acc 0.885\n",
      "train loss 0.116 val loss 0.333 val acc 0.885\n",
      "train loss 0.112 val loss 0.335 val acc 0.886\n",
      "train loss 0.108 val loss 0.337 val acc 0.887\n"
     ]
    }
   ],
   "source": [
    "train_epocs(model, train_dl, epochs=10, lr=0.001)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluation\n",
    "=========="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, sents):\n",
    "    model.eval()\n",
    "    x = np.vstack([encode_sentence(x) for x in sents])\n",
    "    x = torch.LongTensor(x)\n",
    "    h_star, alpha = model(x)    \n",
    "    return alpha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "K = 300\n",
    "sents = X_train[K:K+10]\n",
    "y = y_train[K:K+10]\n",
    "n = [len(x.split(\" \")) for x in sents]\n",
    "alpha= evaluate(model, X_train[K:K+10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(\"the movie occasionally threatens to become didactic , but it's too grounded in the reality of its characters to go over the edge . a touch of humor or an unexpected plot twist always pulls it back .\",\n",
       " 0.0,\n",
       " 38)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "k = 3\n",
    "sents[k], y[k], n[k]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('during his skyrocketing career , johnathan has to experience what alexi has found out : blood brings more viewing pleasure to the audience .',\n",
       " 1.0,\n",
       " 24)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "k = 4\n",
    "sents[k], y[k], n[k]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x1a21d6b668>"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA60AAAA5CAYAAADdus0XAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvOIA7rQAACtxJREFUeJzt3X+wpnVZx/H3h11WDDDYWJEA+zWW2Y4tsRpjjlFIojNFzYSF5dgftjnKjIxDE9WMGeoMNaE10ehsRin9IPxR7DiMieSi/GOc1VX5EbDSmgvbLitQroAEe/XHfZ88nD0/nuc85/a578P7NbNzzvOc7173tXvtd5/neu77+71TVUiSJEmS1EfHTDsBSZIkSZIWY9MqSZIkSeotm1ZJkiRJUm/ZtEqSJEmSesumVZIkSZLUWzatkiRJkqTeGnzTmuSCJHcn2ZPk8mnno/Ek2Zvky0l2J5mZdj5aWpJrkhxMcvuc5zYmuSnJve3Xk6eZoxa2SO3ekeT+dv7tTvKaaeaohSU5M8mnk9yV5I4kb22fd+4NwBL1c/4NQJLjkvxbki+29fvD9vkfSPK5dv79Y5IN085VT7dE7f4myX/MmXtbpp2rlpch36c1yTrgHuB8YB9wG3BxVd051cQ0siR7ga1VdWjauWh5SV4BHAY+VFWb2+f+GHioqq5sPzg6uap+Z5p56miL1O4dwOGq+pNp5qalJTkNOK2qPp/kRGAX8IvAb+Dc670l6vdanH+9lyTA8VV1OMmxwK3AW4G3AR+rquuSvB/4YlW9b5q56umWqN2bgI9X1UemmqDGMvQzrS8F9lTVfVX1BHAdcOGUc5LWrKr6DPDQvKcvBD7Yfv9Bmjdj6plFaqcBqKr9VfX59vtvAHcBp+PcG4Ql6qcBqMbh9uGx7a8CfhaYbXqcfz20RO00QENvWk8Hvjbn8T58IRiaAj6ZZFeSbdNORityalXth+bNGfDcKeej8VyS5Evt5cNeXtpzSb4fOAv4HM69wZlXP3D+DUKSdUl2AweBm4CvAI9U1ZPtEN9/9tT82lXV7Nx7dzv33pvkWVNMUSMaetOaBZ7zE5Rh+amq+gng1cBb2ksYJX1nvA/4IWALsB+4arrpaClJTgA+ClxaVf8z7Xw0ngXq5/wbiKp6qqq2AGfQXOX3owsN+85mpVHMr12SzcDvAi8EXgJsBFxWMQBDb1r3AWfOeXwG8MCUctEKVNUD7deDwD/RvBhoWA60a7Zm124dnHI+GlFVHWhf0I8Af4nzr7fa9VgfBf6uqj7WPu3cG4iF6uf8G56qegTYCZwDnJRkffsj33/23JzaXdBesl9V9S3gr3HuDcLQm9bbgBe0O7htAH4V2DHlnDSiJMe3m1KQ5Hjg54Dbl/5d6qEdwBva798A3DDFXDSG2Yan9Us4/3qp3Uzkr4C7quo9c37k3BuAxern/BuGJJuSnNR+/2zglTTrkj8N/HI7zPnXQ4vU7t/nfNgXmrXIzr0BGPTuwQDtFvF/CqwDrqmqd085JY0oyQ/SnF0FWA/8vfXrtyT/AJwLnAIcAP4A+GfgeuD5wH8CF1WVG/70zCK1O5fm0sQC9gK/NbtGUv2R5OXAZ4EvA0fap3+PZl2kc6/nlqjfxTj/ei/Ji2k2WlpHc7Ln+qq6on0Pcx3N5aVfAH69PXOnnliidv8KbKJZZrgbeNOcDZvUU4NvWiVJkiRJa9fQLw+WJEmSJK1hNq2SJEmSpN6yaZUkSZIk9ZZNqyRJkiSpt2xaJUmSJEm9tWaa1iTbpp2DVsbaDZv1Gy5rN2zWb9is33BZu2GzfsM0UdOaZGOSm5Lc2349eYmxz0lyf5KrJznmEvwHOFzWbtis33BZu2GzfsNm/YbL2g2b9RugSc+0Xg7cXFUvAG5uHy/mncAtEx5PkiRJkvQMkqpa+W9O7gbOrar9SU4DdlbVjyww7mzgt4FPAFur6pIRYtc4HXUBGWHcWaMMWqH7Vv5XuaSN3YTlQEdxAb41xtgjjP7pSVfl6/I6+R87u6sKru8k6oFdB8ca/03g+BHHPjx2NqN5dkdxH+oo7nd3FBfgxDHGHgZOGHHskRXkMopTzx4n43H9cCdRH9+1q5O4/z3m+HHm3tfHjD2qrqq3rqO4AI92FHec1z2Apxjtz/nUCnIZVUdvWzqL26Vxch71Paf6yfr1yxE4VFWblhs36bveU6tqP0DbuD53/oAkxwBXAa8Hzhs18DHAcRMmt5CZDR0EbV007ivWiC7uJizv7SguwN6O4nZVvu/qKC7AzMyrOop8SidR35M/7yQuwEc6ivuijuJe31Hckf8jXIFXdhT3mx3FfdvMOR1FBvhkJ1HvSTdvdz7eSdTGhzqK+zMdxT2po7gAMx3F3dtR3Ec6igvjN9qj6qrR7rKB7+qDuSHq8u9Zmu9R+Ooo45ZtWpN8CnjeAj/6/RFzeTNwY1V9Lcu80LcLo7eBn4BIkiRJkkZoWqtq0Q/ukzyY5Bbge4EHgEMLDHsNcF6Sd9GcQH0iyeGqOmr9a1VtB7YDrEuGeHWJJEmSJGkVTbqU72Hg0XYjpkdZeAnYpcDmqtoAXEZzKfmVEx5XkiRJkvQMMGnTejJwQpJ7afbz2AiQZGuSDwBU1T1VdW87/hHgMWDZxbaSJEmSJE26EdOm9iwrAEkeBqiqGeCNC4y/E3gQ+MpCwVzTKkmSJEmaa9kzrUk+leT2BX5dOGfMBe3tb56T5Ki1qkmeleQG4FaaDdqev9Cxqmp7VW2tqq02rZIkSZKkSTdiOpDkdOAvgNfR7Kp/cZIdVXXnnKFvAV4G/BrNbcn+CPiVSRKXJEmSJK19k14evIPm1jd7aG7XdgPN5kwX0lwKTJIN7Zhrq+rDSdYDVydJVblDsCRJkiRpUZNuxHQl8HLgHOD89vE+YMvsRkzAa2k2aDo/yW6a+3o/BnzPhMeWJEmSJK1xEzWtVfV14J3Ah6vqvKqaveXNwap6Yzvmb2nOur6qqrZU1RbgCZpb3zxNkm1JZpLMeApWkiRJkjTp5cHw7TOrd9OsV90D3DJvzDrgs0m+ARyiuVXOUfd0rartwHaAdYl9qyRJkiQ9w016eTDALuDHgd9sv/40cPu8MZ8Abq6qFwP3AYddzypJkiRJWs5qnGk9G/gS8AGaM6qfATYneQkwU1U7gMuBa5PsAR4HDq7CcSVJkiRJa9xqNK2nA1+YXcOa5PXAT1bVJbMDqupx4KL251cD/7VQoCTbgG0A3qdVkiRJkrQaTWuAM+asad3FImdSk/wZ375n61Fc0ypJkiRJmms11rQ+ALwCeDXwovb7J+cPSvLzNOtedwH/uwrHlSRJkiStcavRtM5eybvomdEkZwHXApcCh1fhmJIkSZKkZ4DVaFqfR7P50r8AdwG3AscmuSLJL7Rj3g8cB7wZ2ApctQrHlSRJkiStcau1pnVfVV0A/78R00ur6u3t42OAx4AXVtXeJDuByxYM5EZMkiRJkqQ5VuNM6z7gzDmPz6BZ5zrrRGAzsDPJXuAcYEeSrfMDVdX2qtpaVVttWiVJkiRJqZpsk94k64F7gPOA+4HbgNdV1R2LjN8JXFZVM8vEfRD46hipnAIcGmO8+sPaDZv1Gy5rN2zWb9is33BZu2Gzfv3yfVW1ablBE18eXFVPJrmEZk3rOuCaqrojyRXATFXtWGHcZZOfK8lMVR119lb9Z+2GzfoNl7UbNus3bNZvuKzdsFm/YVqNNa1U1Y3AjfOee/siY89djWNKkiRJkta+1VjTKkmSJElSJ9ZS07p92gloxazdsFm/4bJ2w2b9hs36DZe1GzbrN0ATb8QkSZIkSVJX1tKZVkmSJEnSGmPTKkmSJEnqLZtWSZIkSVJv2bRKkiRJknrLplWSJEmS1Fv/ByHijpta6LPjAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 1152x144 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.matshow(alpha[k].detach().numpy().transpose(), cmap='hot')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.01005536, 0.02461828, 0.09699872, 0.01900655, 0.00360862,\n",
       "        0.06046836, 0.02709289, 0.05378465, 0.03126656, 0.0727753 ,\n",
       "        0.01021754, 0.00594439, 0.00589792, 0.00724281, 0.00916246,\n",
       "        0.01123917, 0.01324425, 0.01507461, 0.01669827, 0.01811671,\n",
       "        0.01934527, 0.02040414, 0.02131431, 0.02209583, 0.02276696,\n",
       "        0.02334391, 0.02384075, 0.02426954, 0.02464052, 0.02496237,\n",
       "        0.02524234, 0.02548659, 0.02570024, 0.02588763, 0.02605241,\n",
       "        0.02619767, 0.02632601, 0.02643963, 0.02654045, 0.02663008]],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "alpha[k].detach().numpy().transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  },
  "toc": {
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": "block",
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
